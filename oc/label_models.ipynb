{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../metal')\n",
    "sys.path.append('../heart-MRI-pytorch')\n",
    "sys.path.append('../data')\n",
    "sys.path.append('../../sequential_ws')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import logging\n",
    "import warnings\n",
    "import pandas\n",
    "from glob import glob\n",
    "from scipy.sparse import csr_matrix\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import normalize\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from utils import *\n",
    "from metal.metrics import metric_score\n",
    "from metal.label_model import LabelModel\n",
    "from metal.label_model.baselines import MajorityLabelVoter\n",
    "from metal.analysis import lf_summary, confusion_matrix\n",
    "from DP.label_model import DPLabelModel, optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(label_list):\n",
    "    '''\n",
    "    Function to read labels given list of labels\n",
    "    Returns a sparse matrix for LFs\n",
    "    Returns numpy array for true labels\n",
    "    \n",
    "    Input\n",
    "    ----\n",
    "    label_list: list of labels\n",
    "    \n",
    "    Output\n",
    "    -----\n",
    "    L: sparse matrix (#patients*#frames, #LFs)\n",
    "    or L: numpy array (#patients*#frames,)\n",
    "    '''\n",
    "    \n",
    "    L = []\n",
    "    for index in range(len(label_list)):\n",
    "        L.append(np.load(label_list[index]))\n",
    "\n",
    "    L = np.squeeze(np.array(L))\n",
    "    \n",
    "    # reshaping array from (PID,frames,) -> (PID*frames,)\n",
    "    m = L.shape[0]\n",
    "    n = L.shape[1]\n",
    "    if(len(L.shape) == 2): # true labels \n",
    "        L = np.reshape(L,(m*n,))\n",
    "        L = L+1 # changing from 0-indexing to 1-indexing\n",
    "    else:\n",
    "        L = csr_matrix(np.reshape(L,(m*n,L.shape[2])))\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(args):\n",
    "    '''\n",
    "    Script to read labels using input args\n",
    "    '''\n",
    "    L = {}\n",
    "    Y = {}\n",
    "\n",
    "    #train_lf_list = glob(args.train + '/lf_labels/*.npy') \n",
    "    L[\"train\"] = read_labels(glob(args[\"train\"] + '/lf_labels/*.npy'))\n",
    "    L[\"dev\"] = read_labels(glob(args[\"dev\"] + '/lf_labels/*.npy'))\n",
    "    L[\"test\"] = read_labels(glob(args[\"test\"] + '/lf_labels/*.npy'))\n",
    "\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    Y[\"dev\"] = read_labels(glob(args[\"dev\"] + '/true_labels/*.npy'))\n",
    "    Y[\"test\"] = read_labels(glob(args[\"test\"] + '/true_labels/*.npy'))\t\n",
    "\n",
    "    return L,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "args = {}\n",
    "args[\"train\"] = '../data/open_close/train'\n",
    "args[\"dev\"] = '../data/open_close/dev'\n",
    "args[\"test\"] = '../data/open_close/test'\n",
    "\n",
    "L,Y = load_labels(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(L[\"train\"].todense().shape) # (18850,5)\n",
    "#print(L[\"dev\"].todense().shape) # (1500,5)\n",
    "#print(Y[\"dev\"].shape) # (1500,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Polarity  Coverage  Overlaps  Conflicts  Correct  Incorrect  Emp. Acc.\n",
      "0  [1.0, 2.0]       1.0       1.0   0.212667     1359        141   0.906000\n",
      "1  [1.0, 2.0]       1.0       1.0   0.212667     1312        188   0.874667\n",
      "2  [1.0, 2.0]       1.0       1.0   0.212667     1361        139   0.907333\n",
      "3  [1.0, 2.0]       1.0       1.0   0.212667     1309        191   0.872667\n",
      "4  [1.0, 2.0]       1.0       1.0   0.212667     1377        123   0.918000\n"
     ]
    }
   ],
   "source": [
    "# labelling functions analysis\n",
    "print(lf_summary(L[\"dev\"], Y = Y[\"dev\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Label Voter Metrics:\n",
      "Accuracy: 0.915\n",
      "Precision: 0.894\n",
      "Recall: 0.920\n",
      "F1: 0.907\n",
      "        y=1    y=2   \n",
      " l=1    625    74    \n",
      " l=2    54     747   \n"
     ]
    }
   ],
   "source": [
    "# majority vote of LFs\n",
    "mv = MajorityLabelVoter(seed=123)\n",
    "print('Majority Label Voter Metrics:')\n",
    "mv_score = mv.score((L[\"dev\"], Y[\"dev\"]), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metal Label Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# defining parameters\n",
    "num_classes = 2\n",
    "if (torch.cuda.is_available()):\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[50 epo]: TRAIN:[loss=0.017]\n",
      "[100 epo]: TRAIN:[loss=0.002]\n",
      "[150 epo]: TRAIN:[loss=0.002]\n",
      "[200 epo]: TRAIN:[loss=0.002]\n",
      "[250 epo]: TRAIN:[loss=0.002]\n",
      "[300 epo]: TRAIN:[loss=0.002]\n",
      "[350 epo]: TRAIN:[loss=0.002]\n",
      "[400 epo]: TRAIN:[loss=0.002]\n",
      "[450 epo]: TRAIN:[loss=0.002]\n",
      "[500 epo]: TRAIN:[loss=0.002]\n",
      "Finished Training\n",
      "Trained Label Model Metrics:\n",
      "Accuracy: 0.913\n",
      "Precision: 0.885\n",
      "Recall: 0.928\n",
      "F1: 0.906\n",
      "        y=1    y=2   \n",
      " l=1    630    82    \n",
      " l=2    49     739   \n"
     ]
    }
   ],
   "source": [
    "# training label model - no temporal modelling\n",
    "label_model = LabelModel(k=num_classes, seed=123)\n",
    "label_model.train_model(L[\"train\"], Y[\"dev\"], n_epochs = 500, log_train_every = 50)\n",
    "\n",
    "# evaluating label model\n",
    "print('Trained Label Model Metrics:')\n",
    "lm_score = label_model.score((L[\"dev\"], Y[\"dev\"]), metric=['accuracy','precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training label model without temporal modelling\n",
    "# ( this should reproduce the results above )\n",
    "m_per_task = L[\"train\"].todense().shape[1] # 5\n",
    "MRI_data_naive = {'Li_train': torch.LongTensor(np.array(L[\"train\"].todense().astype(int))),\n",
    "                'Li_dev': torch.LongTensor(np.array(L[\"dev\"].todense().astype(int))),\n",
    "                'R_dev':Y[\"dev\"]}\n",
    "\n",
    "MRI_data_naive['class_balance'] = torch.FloatTensor([0.5,0.5]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration=0 loss=55.706329345703125\n",
      "iteration=300 loss=0.08146391808986664\n",
      "iteration=600 loss=0.0741795152425766\n",
      "iteration=900 loss=0.06845731288194656\n",
      "iteration=1200 loss=0.06415102630853653\n",
      "iteration=1500 loss=0.06096632033586502\n",
      "iteration=1800 loss=0.05861331522464752\n",
      "iteration=2100 loss=0.05686088278889656\n",
      "iteration=2400 loss=0.05554001033306122\n",
      "iteration=2700 loss=0.05453081429004669\n",
      "iteration=2999 loss=0.05400734022259712\n"
     ]
    }
   ],
   "source": [
    "# training naive model \n",
    "naive_model = DPLabelModel(m=m_per_task, \n",
    "                       T=1,\n",
    "                       edges=[],\n",
    "                       coverage_sets=[[0,]]*m_per_task,\n",
    "                       mu_sharing=[[i,] for i in range(m_per_task)],\n",
    "                       phi_sharing=[],\n",
    "                       device=device,\n",
    "                       class_balance=MRI_data_naive['class_balance'], \n",
    "                       seed=0)\n",
    "\n",
    "optimize(naive_model, L_hat=MRI_data_naive['Li_train'], num_iter=3000, lr=1e-3, momentum=0.8, clamp=True, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #2 'mat2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4c065683800d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluating naive model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnaive_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mR_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnaive_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mMRI_data_naive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Li_dev'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mR_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mR_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#print(R_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/ashwinir/sequential_ws/DP/label_model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Li)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mDPLabelModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeasible_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mY_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_proba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/ashwinir/sequential_ws/DP/label_model.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, Li)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_computed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                 \u001b[0mconditional_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconditional_P\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba_unconditioned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m                 \u001b[0mis_computed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mjoint_P\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconditional_P\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_balance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/dfs/scratch0/ashwinir/sequential_ws/DP/label_model.py\u001b[0m in \u001b[0;36mpredict_proba_unconditioned\u001b[0;34m(self, Li, i)\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mabstain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoverage_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoverage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'abstain_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0mis_abstain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mLi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mabstain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mP_abstain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_abstain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mis_abstain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLF_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLF_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r_prime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConstantPad2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLF_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLF_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r_prime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mP_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #2 'mat2'"
     ]
    }
   ],
   "source": [
    "# evaluating naive model \n",
    "naive_model = naive_model.cuda()\n",
    "R_pred = naive_model.predict( MRI_data_naive['Li_dev'] ).data.numpy()\n",
    "R_pred = 2 - R_pred\n",
    "#print(R_pred)\n",
    "#print(MRI_data_naive['R_dev'])\n",
    "\n",
    "for metric in ['accuracy', 'f1', 'recall', 'precision']:\n",
    "    score = metric_score(MRI_data_naive['R_dev'], R_pred, metric)\n",
    "    print(f\"{metric.capitalize()}: {score:.3f}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training label model with temporal modelling\n",
    "# reshaping dataset\n",
    "num_frames = 50\n",
    "n_patients_train = round(L[\"train\"].todense().shape[0]/num_frames) #(377)\n",
    "n_patients_dev = round(L[\"dev\"].todense().shape[0]/num_frames) #(30)\n",
    "Ltrain = np.reshape(np.array(L[\"train\"].todense()),(n_patients_train,num_frames,-1))\n",
    "Ldev = np.reshape(np.array(L[\"dev\"].todense()),(n_patients_dev,num_frames,-1))\n",
    "Ydev = np.reshape(Y[\"dev\"],(n_patients_dev,num_frames))\n",
    "# print(Ltrain.shape) # (377,50,5)\n",
    "#print(Ldev.shape) # (30,50,5)\n",
    "#print(Ydev.shape) # (30,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsampling\n",
    "# selecting frames 3,13,23,33,43\n",
    "indices = np.linspace(2,42,5).astype(int)\n",
    "m_per_task = 5\n",
    "T = 5\n",
    "\n",
    "Ltrain_small = Ltrain[:,indices,:] # shape (377,5,5)\n",
    "Ldev_small = Ldev[:,indices,:] # shape (30,5,5)\n",
    "Ydev_small = Ydev[:,indices] # shape (30,5)\n",
    "\n",
    "Ltrain_small = np.reshape(Ltrain_small,((n_patients_train*T),m_per_task)) # shape (1885,5)\n",
    "Ldev_small = np.reshape(Ldev_small,((n_patients_dev*T),m_per_task)) # shape (150,5)\n",
    "Ydev_small = np.reshape(Ydev_small,((n_patients_dev*T),)) # shape (150,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MRI_data_temporal = {'Li_train': torch.LongTensor(Ltrain_small).view(n_patients_train, (m_per_task*T)), \n",
    "                    'Li_dev': torch.LongTensor(Ldev_small).view(n_patients_dev, (m_per_task*T)), \n",
    "                    'R_dev':torch.LongTensor(Ydev_small)[::T]*(2**T-1),\n",
    "                    'm': m_per_task*T,\n",
    "                    'T': T }\n",
    "\n",
    "MRI_data_temporal['class_balance'] = normalize((MRI_data_temporal['R_dev'].unsqueeze(1)==torch.arange(2**T, device=device).unsqueeze(0)).sum(0).float(), \n",
    "                                                dim=0, p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seed = 10\n",
    "temporal_models = [None,]*max_seed\n",
    "for seed in range(max_seed):\n",
    "    markov_model = DPLabelModel(m=m_per_task*T, \n",
    "                                T=T,\n",
    "                                edges=[(i,i+m_per_task) for i in range((T-1)*m_per_task)],\n",
    "                                coverage_sets=[[t,] for t in range(T) for _ in range(m_per_task)],\n",
    "                                mu_sharing=[[t*m_per_task+i for t in range(T)] for i in range(m_per_task)],\n",
    "                                phi_sharing=[[(t*m_per_task+i, (t+1)*m_per_task+i) for t in range(T-1)] for i in range(m_per_task)],\n",
    "                                device=device,\n",
    "                                class_balance=MRI_data_temporal['class_balance'],\n",
    "                                seed=seed)\n",
    "    optimize(markov_model, L_hat=MRI_data_temporal['Li_train'], num_iter=1000, lr=1e-5, momentum=0.8, clamp=True, \n",
    "             verbose=False, seed=seed)\n",
    "    temporal_models[seed] = markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed, model in enumerate(temporal_models):\n",
    "    R_pred = model.predict(MRI_data_temporal['Li_dev'])\n",
    "    F1 = metric_score(MRI_data_temporal['R_dev'].cpu()>0, R_pred.cpu()>0, 'f1')\n",
    "    accuracy = metric_score(MRI_data_temporal['R_dev'].cpu(), R_pred.cpu(), 'accuracy')\n",
    "    print(f\"seed={seed}  accuracy={accuracy:.3f}  F1={F1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
